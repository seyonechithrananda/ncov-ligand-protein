{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression_Scaffold_AttentionFP_ncov.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "112Bh4DGVXPD-ZyqDU3AC8pJbxVKaUth6",
      "authorship_tag": "ABX9TyO/GapXvDuGGL9vgNc53Crf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyonechithrananda/ncov-ligand-protein/blob/master/Regression_Scaffold_AttentionFP_ncov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnhZ7HBLDf73",
        "colab_type": "code",
        "outputId": "d796afd0-f23f-4889-b390-18dac161b326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c conda-forge rdkit\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-06 16:32:49--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85055499 (81M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  81.12M   178MB/s    in 0.5s    \n",
            "\n",
            "2020-05-06 16:32:49 (178 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [85055499/85055499]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.72.0               |   py37h9de70de_0         316 KB  conda-forge\n",
            "    boost-cpp-1.72.0           |       h8e57a91_0        21.8 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2020.4.5.1 |       hecc5488_0         146 KB  conda-forge\n",
            "    cairo-1.16.0               |    hcf35c78_1003         1.5 MB  conda-forge\n",
            "    certifi-2020.4.5.1         |   py37hc8dfbb8_0         151 KB  conda-forge\n",
            "    conda-4.8.3                |   py37hc8dfbb8_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.1            |       he06d7ca_0         877 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.64.2                |       h6f030ca_0         3.4 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_5         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1006         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_6         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_1         308 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc7e4089_6         668 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libwebp-base-1.1.0         |       h516909a_3         845 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    numpy-1.18.4               |   py37h8960a57_0         5.2 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-1.0.3               |   py37h0da4684_1        11.1 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-7.1.2               |   py37hb39fc2d_0         603 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.19.1             |   py37h01af8b0_3          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    pytz-2020.1                |     pyh9f0ad1d_0         227 KB  conda-forge\n",
            "    rdkit-2020.03.1            |   py37hdd87690_3        24.6 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h3b9ef0a_2         982 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       110.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.72.0-py37h9de70de_0\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.72.0-h8e57a91_0\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hcf35c78_1003\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.1-he06d7ca_0\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.64.2-h6f030ca_0\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_5\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1006\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_6\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_1\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  numpy              conda-forge/linux-64::numpy-1.18.4-py37h8960a57_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.0.3-py37h0da4684_1\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-7.1.2-py37hb39fc2d_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.19.1-py37h01af8b0_3\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  pytz               conda-forge/noarch::pytz-2020.1-pyh9f0ad1d_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2020.03.1-py37hdd87690_3\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h3b9ef0a_2\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.4.5.1-hecc5488_0\n",
            "  certifi              pkgs/main::certifi-2019.11.28-py37_0 --> conda-forge::certifi-2020.4.5.1-py37hc8dfbb8_0\n",
            "  conda                       pkgs/main::conda-4.8.2-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxPjaPjsGNGb",
        "colab_type": "code",
        "outputId": "6e623f8b-df9a-4e97-bc49-ebeeaeb1413e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        }
      },
      "source": [
        "!conda install -c dglteam dgl-cuda10.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - dgl-cuda10.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |         openblas          46 KB\n",
            "    certifi-2020.4.5.1         |           py37_0         155 KB\n",
            "    decorator-4.4.2            |             py_0          14 KB\n",
            "    dgl-cuda10.1-0.4.3post2    |           py37_0        11.2 MB  dglteam\n",
            "    networkx-2.4               |             py_0         1.2 MB\n",
            "    scipy-1.4.1                |   py37habc2bb6_0        14.6 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        27.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-openblas\n",
            "  decorator          pkgs/main/noarch::decorator-4.4.2-py_0\n",
            "  dgl-cuda10.1       dglteam/linux-64::dgl-cuda10.1-0.4.3post2-py37_0\n",
            "  networkx           pkgs/main/noarch::networkx-2.4-py_0\n",
            "  scipy              pkgs/main/linux-64::scipy-1.4.1-py37habc2bb6_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  certifi            conda-forge::certifi-2020.4.5.1-py37h~ --> pkgs/main::certifi-2020.4.5.1-py37_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "scipy-1.4.1          | 14.6 MB   | : 100% 1.0/1 [00:00<00:00,  1.52it/s]             \n",
            "blas-1.0             | 46 KB     | : 100% 1.0/1 [00:00<00:00, 23.41it/s]\n",
            "networkx-2.4         | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  3.28it/s]\n",
            "decorator-4.4.2      | 14 KB     | : 100% 1.0/1 [00:00<00:00, 23.11it/s]\n",
            "certifi-2020.4.5.1   | 155 KB    | : 100% 1.0/1 [00:00<00:00, 22.31it/s]\n",
            "dgl-cuda10.1-0.4.3po | 11.2 MB   | : 100% 1.0/1 [00:08<00:00,  8.98s/it]               \n",
            "Preparing transaction: | \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ba7Nw5eGUTr",
        "colab_type": "code",
        "outputId": "6e226046-6712-416e-c801-0b619ea92b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "!conda install -c dglteam dgllife\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - dgllife\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    dgllife-0.2.1              |           py37_0         132 KB  dglteam\n",
            "    joblib-0.14.1              |             py_0         201 KB\n",
            "    scikit-learn-0.22.1        |   py37h22eb022_0         5.3 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         5.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  dgllife            dglteam/linux-64::dgllife-0.2.1-py37_0\n",
            "  joblib             pkgs/main/noarch::joblib-0.14.1-py_0\n",
            "  scikit-learn       pkgs/main/linux-64::scikit-learn-0.22.1-py37h22eb022_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "scikit-learn-0.22.1  | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.45it/s]               \n",
            "dgllife-0.2.1        | 132 KB    | : 100% 1.0/1 [00:02<00:00,  2.32s/it]               \n",
            "joblib-0.14.1        | 201 KB    | : 100% 1.0/1 [00:00<00:00, 17.98it/s]\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqRn8KexGdiL",
        "colab_type": "code",
        "outputId": "3f697268-15c0-47dc-e1d8-622363a7dc92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        }
      },
      "source": [
        "!conda install pandas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pandas\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    conda-4.8.3                |           py37_0         2.8 MB\n",
            "    openssl-1.1.1g             |       h7b6447c_0         2.5 MB\n",
            "    pandas-1.0.3               |   py37h0573a6f_0         8.6 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        13.9 MB\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2020.4.5~ --> pkgs/main::ca-certificates-2020.1.1-0\n",
            "  conda              conda-forge::conda-4.8.3-py37hc8dfbb8~ --> pkgs/main::conda-4.8.3-py37_0\n",
            "  openssl            conda-forge::openssl-1.1.1g-h516909a_0 --> pkgs/main::openssl-1.1.1g-h7b6447c_0\n",
            "  pandas             conda-forge::pandas-1.0.3-py37h0da468~ --> pkgs/main::pandas-1.0.3-py37h0573a6f_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "openssl-1.1.1g       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  5.91it/s]\n",
            "conda-4.8.3          | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  6.07it/s]\n",
            "pandas-1.0.3         | 8.6 MB    | : 100% 1.0/1 [00:00<00:00,  2.04it/s]\n",
            "Preparing transaction: \\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVKD7kwtHDUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "import sys \n",
        "import pandas as pd\n",
        "\n",
        "# train --> balanced dataset\n",
        "dataset_train_file = \"/content/drive/My Drive/Project De Novo/AID1706_binarized_sars_full_eval_actives_12k_samples.csv\"\n",
        "dataset_eval_file = \"/content/drive/My Drive/Project De Novo/mpro_xchem.csv\"\n",
        "dataset_train = pd.read_csv(dataset_train_file)\n",
        "dataset_eval = pd.read_csv(dataset_eval_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy7_zDz9LCq2",
        "colab_type": "code",
        "outputId": "62ab2caa-9a85-46f4-9b13-cf2ad2c4945d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "dataset_train.head"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                   smiles  activity\n",
              "0      C1CC(C1)C(=O)NC2=CC=C(C=C2)N(C(C3=CC(=CC=C3)F)...         1\n",
              "1      CC(C)(C)C1=CC=C(C=C1)N(C(C2=CN=NC=C2)C(=O)NC(C...         1\n",
              "2      CC(C)(C)NC(=O)C(C1=CSC=C1)N(C2=CC=C(C=C2)N)C(=...         1\n",
              "3      CC(C)C(=O)NC1=CC=C(C=C1)N(C(C2=CSC=C2)C(=O)NC(...         1\n",
              "4      CC(C)C(=O)NC1=CC=C(C=C1)N(CC2=CSC=C2)C(=O)CN3C...         1\n",
              "...                                                  ...       ...\n",
              "11994                               C1=CC2=C(C=C1N)NN=C2         0\n",
              "11995  CC(=O)[C@H]1CC[C@@H]2[C@@]1(CC(=O)[C@H]3[C@H]2...         0\n",
              "11996                       C1CN(CCN1CC(CO)O)C2=CC=CC=C2         0\n",
              "11997  CCOC(=O)N1CCC(=C2C3=C(CCC4=C2N=CC=C4)C=C(C=C3)...         0\n",
              "11998                    C1=CC2=C(C=C1OC(F)(F)F)SC(=N2)N         0\n",
              "\n",
              "[11999 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBnPl4isM1FQ",
        "colab_type": "code",
        "outputId": "723b663a-82f7-4051-8f3a-bbdda05dae45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "dataset_eval.head"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                 smiles  activity\n",
              "0      OC=1C=CC=CC1CNC2=NC=3C=CC=CC3N2         1\n",
              "1        CC(=O)NCCC1=CNC=2C=CC(F)=CC12         1\n",
              "2    O=C([C@@H]1[C@H](C2=CSC=C2)CCC1)N         1\n",
              "3       CN1CCCC=2C=CC(=CC12)S(=O)(=O)N         1\n",
              "4     CC(=O)NC=1C=CC(OC=2N=CC=CN2)=CC1         1\n",
              "..                                 ...       ...\n",
              "875   CC(C)C=1C=CC(NC(=O)N2CCOCC2)=CC1         0\n",
              "876        CN(CC(=O)O)C(=O)C=1C=CC=CN1         0\n",
              "877  CN1CCN(CC1)C(=O)C=2C=CC(F)=C(F)C2         0\n",
              "878      FC=1C=CC=C(F)C1C(=O)N2CCCCCC2         0\n",
              "879             FC=1C=CC=NC1NCC2CCOCC2         0\n",
              "\n",
              "[880 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1TtgCu8U26K",
        "colab_type": "code",
        "outputId": "f4508a1c-2bc1-4a9a-aeb0-084da106c91f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7a2cc6fc-7054-418c-aa5b-ca974c66eb14\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7a2cc6fc-7054-418c-aa5b-ca974c66eb14\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving utils.py to utils.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'utils.py': b'import dgl\\nimport numpy as np\\nimport random\\nimport torch\\n\\nfrom dgllife.utils.featurizers import one_hot_encoding\\nfrom dgllife.utils.splitters import RandomSplitter\\n\\ndef set_random_seed(seed=0):\\n    \"\"\"Set random seed.\\n    Parameters\\n    ----------\\n    seed : int\\n        Random seed to use\\n    \"\"\"\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.manual_seed(seed)\\n    if torch.cuda.is_available():\\n        torch.cuda.manual_seed(seed)\\n\\n\\ndef load_dataset_for_classification(args):\\n    \"\"\"Load dataset for classification tasks.\\n    Parameters\\n    ----------\\n    args : dict\\n        Configurations.\\n    Returns\\n    -------\\n    dataset\\n        The whole dataset.\\n    train_set\\n        Subset for training.\\n    val_set\\n        Subset for validation.\\n    test_set\\n        Subset for test.\\n    \"\"\"\\n    assert args[\\'dataset\\'] in [\\'Tox21\\']\\n    if args[\\'dataset\\'] == \\'Tox21\\':\\n        from dgllife.data import Tox21\\n        dataset = Tox21(smiles_to_graph=args[\\'smiles_to_graph\\'],\\n                        node_featurizer=args.get(\\'node_featurizer\\', None),\\n                        edge_featurizer=args.get(\\'edge_featurizer\\', None))\\n        train_set, val_set, test_set = RandomSplitter.train_val_test_split(\\n            dataset, frac_train=args[\\'frac_train\\'], frac_val=args[\\'frac_val\\'],\\n            frac_test=args[\\'frac_test\\'], random_state=args[\\'random_seed\\'])\\n\\n    return dataset, train_set, val_set, test_set\\n\\n\\ndef load_dataset_for_regression(args):\\n    \"\"\"Load dataset for regression tasks.\\n    Parameters\\n    ----------\\n    args : dict\\n        Configurations.\\n    Returns\\n    -------\\n    train_set\\n        Subset for training.\\n    val_set\\n        Subset for validation.\\n    test_set\\n        Subset for test.\\n    \"\"\"\\n    assert args[\\'dataset\\'] in [\\'Alchemy\\', \\'Aromaticity\\']\\n\\n    if args[\\'dataset\\'] == \\'Alchemy\\':\\n        from dgllife.data import TencentAlchemyDataset\\n        train_set = TencentAlchemyDataset(mode=\\'dev\\')\\n        val_set = TencentAlchemyDataset(mode=\\'valid\\')\\n        test_set = None\\n\\n    if args[\\'dataset\\'] == \\'Aromaticity\\':\\n        from dgllife.data import PubChemBioAssayAromaticity\\n        dataset = PubChemBioAssayAromaticity(smiles_to_graph=args[\\'smiles_to_graph\\'],\\n                                             node_featurizer=args.get(\\'node_featurizer\\', None),\\n                                             edge_featurizer=args.get(\\'edge_featurizer\\', None))\\n        train_set, val_set, test_set = RandomSplitter.train_val_test_split(\\n            dataset, frac_train=args[\\'frac_train\\'], frac_val=args[\\'frac_val\\'],\\n            frac_test=args[\\'frac_test\\'], random_state=args[\\'random_seed\\'])\\n\\n    return train_set, val_set, test_set\\n\\n\\ndef collate_molgraphs(data):\\n    \"\"\"Batching a list of datapoints for dataloader.\\n    Parameters\\n    ----------\\n    data : list of 3-tuples or 4-tuples.\\n        Each tuple is for a single datapoint, consisting of\\n        a SMILES, a DGLGraph, all-task labels and optionally\\n        a binary mask indicating the existence of labels.\\n    Returns\\n    -------\\n    smiles : list\\n        List of smiles\\n    bg : DGLGraph\\n        The batched DGLGraph.\\n    labels : Tensor of dtype float32 and shape (B, T)\\n        Batched datapoint labels. B is len(data) and\\n        T is the number of total tasks.\\n    masks : Tensor of dtype float32 and shape (B, T)\\n        Batched datapoint binary mask, indicating the\\n        existence of labels. If binary masks are not\\n        provided, return a tensor with ones.\\n    \"\"\"\\n    assert len(data[0]) in [3, 4], \\\\\\n        \\'Expect the tuple to be of length 3 or 4, got {:d}\\'.format(len(data[0]))\\n    if len(data[0]) == 3:\\n        smiles, graphs, labels = map(list, zip(*data))\\n        masks = None\\n    else:\\n        smiles, graphs, labels, masks = map(list, zip(*data))\\n\\n    bg = dgl.batch(graphs)\\n    bg.set_n_initializer(dgl.init.zero_initializer)\\n    bg.set_e_initializer(dgl.init.zero_initializer)\\n    labels = torch.stack(labels, dim=0)\\n\\n    if masks is None:\\n        masks = torch.ones(labels.shape)\\n    else:\\n        masks = torch.stack(masks, dim=0)\\n    return smiles, bg, labels, masks\\n\\n\\ndef load_model(args):\\n    if args[\\'model\\'] == \\'GCN\\':\\n        from dgllife.model import GCNPredictor\\n        model = GCNPredictor(in_feats=args[\\'node_featurizer\\'].feat_size(),\\n                             hidden_feats=args[\\'gcn_hidden_feats\\'],\\n                             classifier_hidden_feats=args[\\'classifier_hidden_feats\\'],\\n                             n_tasks=args[\\'n_tasks\\'])\\n\\n    if args[\\'model\\'] == \\'GAT\\':\\n        from dgllife.model import GATPredictor\\n        model = GATPredictor(in_feats=args[\\'node_featurizer\\'].feat_size(),\\n                             hidden_feats=args[\\'gat_hidden_feats\\'],\\n                             num_heads=args[\\'num_heads\\'],\\n                             classifier_hidden_feats=args[\\'classifier_hidden_feats\\'],\\n                             n_tasks=args[\\'n_tasks\\'])\\n\\n    if args[\\'model\\'] == \\'Weave\\':\\n        from dgllife.model import WeavePredictor\\n        model = WeavePredictor(node_in_feats=args[\\'node_featurizer\\'].feat_size(),\\n                               edge_in_feats=args[\\'edge_featurizer\\'].feat_size(),\\n                               num_gnn_layers=args[\\'num_gnn_layers\\'],\\n                               gnn_hidden_feats=args[\\'gnn_hidden_feats\\'],\\n                               graph_feats=args[\\'graph_feats\\'],\\n                               n_tasks=args[\\'n_tasks\\'])\\n\\n    if args[\\'model\\'] == \\'AttentiveFP\\':\\n        from dgllife.model import AttentiveFPPredictor\\n        model = AttentiveFPPredictor(node_feat_size=args[\\'node_featurizer\\'].feat_size(),\\n                                     edge_feat_size=args[\\'edge_featurizer\\'].feat_size(),\\n                                     num_layers=args[\\'num_layers\\'],\\n                                     num_timesteps=args[\\'num_timesteps\\'],\\n                                     graph_feat_size=args[\\'graph_feat_size\\'],\\n                                     n_tasks=args[\\'n_tasks\\'],\\n                                     dropout=args[\\'dropout\\'])\\n\\n    if args[\\'model\\'] == \\'SchNet\\':\\n        from dgllife.model import SchNetPredictor\\n        model = SchNetPredictor(node_feats=args[\\'node_feats\\'],\\n                                hidden_feats=args[\\'hidden_feats\\'],\\n                                classifier_hidden_feats=args[\\'classifier_hidden_feats\\'],\\n                                n_tasks=args[\\'n_tasks\\'])\\n\\n    if args[\\'model\\'] == \\'MGCN\\':\\n        from dgllife.model import MGCNPredictor\\n        model = MGCNPredictor(feats=args[\\'feats\\'],\\n                              n_layers=args[\\'n_layers\\'],\\n                              classifier_hidden_feats=args[\\'classifier_hidden_feats\\'],\\n                              n_tasks=args[\\'n_tasks\\'])\\n\\n    if args[\\'model\\'] == \\'MPNN\\':\\n        from dgllife.model import MPNNPredictor\\n        model = MPNNPredictor(node_in_feats=args[\\'node_in_feats\\'],\\n                              edge_in_feats=args[\\'edge_in_feats\\'],\\n                              node_out_feats=args[\\'node_out_feats\\'],\\n                              edge_hidden_feats=args[\\'edge_hidden_feats\\'],\\n                              n_tasks=args[\\'n_tasks\\'])\\n\\n    return model\\n\\n\\ndef chirality(atom):\\n    try:\\n        return one_hot_encoding(atom.GetProp(\\'_CIPCode\\'), [\\'R\\', \\'S\\']) + \\\\\\n               [atom.HasProp(\\'_ChiralityPossible\\')]\\n    except:\\n        return [False, False] + [atom.HasProp(\\'_ChiralityPossible\\')]\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVrUoqtTHGy8",
        "colab_type": "code",
        "outputId": "835b3ec2-9e6b-4f94-aa39-b2adeabf9f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "from dgllife.data import MoleculeCSVDataset\n",
        "from dgllife.data.csv_dataset import *\n",
        "from dgllife.utils.featurizers import *\n",
        "from dgllife.utils.mol_to_graph import *\n",
        "\n",
        "from dgllife.utils import ConcatFeaturizer\n",
        "# node featurization\n",
        "from dgllife.utils import CanonicalAtomFeaturizer, BaseAtomFeaturizer, atom_type_one_hot, atom_degree_one_hot, atom_formal_charge, atom_num_radical_electrons, atom_hybridization_one_hot, atom_total_num_H_one_hot\n",
        "# edge featurization\n",
        "from dgllife.utils.featurizers import BaseBondFeaturizer\n",
        "from functools import partial\n",
        "from utils import chirality\n",
        "\n",
        "\n",
        "# featurize bigraph/molecular graph set for train (SARS-COV-1) set\n",
        "train_set = MoleculeCSVDataset(dataset_train, smiles_to_graph=smiles_to_bigraph, node_featurizer=BaseAtomFeaturizer(featurizer_funcs={'hv': ConcatFeaturizer([\n",
        "            partial(atom_type_one_hot, allowable_set=[\n",
        "                'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br', 'Te', 'I', 'At'],\n",
        "                    encode_unknown=True),\n",
        "            partial(atom_degree_one_hot, allowable_set=list(range(6))),\n",
        "            atom_formal_charge, atom_num_radical_electrons,\n",
        "            partial(atom_hybridization_one_hot, encode_unknown=True),\n",
        "            lambda atom: [0], # A placeholder for aromatic information,\n",
        "            atom_total_num_H_one_hot, chirality],)}),\n",
        "            edge_featurizer=BaseBondFeaturizer({'he': lambda bond: [0 for _ in range(10)]}), \n",
        "            smiles_column='smiles', cache_file_path='/content/drive/My Drive/Project De Novo/AttentionFP/train.bin', task_names=['activity'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Loading previously saved dgl graphs...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofwpNYUXJASi",
        "colab_type": "code",
        "outputId": "e210d144-edbe-48a3-d897-2dbe416e15c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# featurize bigraph/molecular graph set for test (SARS-COV-2) set\n",
        "test_set = MoleculeCSVDataset(dataset_eval, smiles_to_graph=smiles_to_bigraph, node_featurizer=BaseAtomFeaturizer(featurizer_funcs={'hv': ConcatFeaturizer([\n",
        "            partial(atom_type_one_hot, allowable_set=[\n",
        "                'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br', 'Te', 'I', 'At'],\n",
        "                    encode_unknown=True),\n",
        "            partial(atom_degree_one_hot, allowable_set=list(range(6))),\n",
        "            atom_formal_charge, atom_num_radical_electrons,\n",
        "            partial(atom_hybridization_one_hot, encode_unknown=True),\n",
        "            lambda atom: [0], # A placeholder for aromatic information,\n",
        "            atom_total_num_H_one_hot, chirality],)}),\n",
        "            edge_featurizer=BaseBondFeaturizer({'he': lambda bond: [0 for _ in range(10)]}), smiles_column='smiles', cache_file_path='/content/drive/My Drive/Project De Novo/AttentionFP/test.bin', task_names=['activity'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading previously saved dgl graphs...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKMgchzflhiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    'random_seed': 8,\n",
        "    'graph_feat_size': 200,\n",
        "    'num_layers': 2,\n",
        "    'num_timesteps': 2,\n",
        "    'node_feat_size': 39,\n",
        "    'edge_feat_size': 10,\n",
        "    'node_data_field':'hv',\n",
        "    'edge_data_field':'he',\n",
        "    'n_tasks': 1,\n",
        "    'dropout': 0.2,\n",
        "    'weight_decay': 10 ** (-5.0),\n",
        "    'lr': 10 ** (-2.5),\n",
        "    'batch_size': 128,\n",
        "    'num_epochs': 800,\n",
        "    'frac_train': 0.8,\n",
        "    'frac_val': 0.1,\n",
        "    'frac_test': 0.1,\n",
        "    'patience': 80,\n",
        "    'model' : 'AttentiveFPPredictor',\n",
        "    'metric_name': 'roc_auc_score',\n",
        "    'smiles_to_graph': smiles_to_bigraph,\n",
        "    # Follow the atom featurization in the original work\n",
        "    'node_featurizer': BaseAtomFeaturizer(\n",
        "        featurizer_funcs={'hv': ConcatFeaturizer([\n",
        "            partial(atom_type_one_hot, allowable_set=[\n",
        "                'B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br', 'Te', 'I', 'At'],\n",
        "                    encode_unknown=True),\n",
        "            partial(atom_degree_one_hot, allowable_set=list(range(6))),\n",
        "            atom_formal_charge, atom_num_radical_electrons,\n",
        "            partial(atom_hybridization_one_hot, encode_unknown=True),\n",
        "            lambda atom: [0], # A placeholder for aromatic information,\n",
        "            atom_total_num_H_one_hot, chirality\n",
        "        ],\n",
        "        )}\n",
        "    ),\n",
        "    'edge_featurizer': BaseBondFeaturizer({\n",
        "        'he': lambda bond: [0 for _ in range(10)]\n",
        "    })\n",
        "}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuZkFAz-PDvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import utils\n",
        "\n",
        "from dgllife.model import load_pretrained\n",
        "from dgllife.utils import EarlyStopping, Meter\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "from utils import set_random_seed, load_dataset_for_classification, collate_molgraphs, load_model\n",
        "\n",
        "from dgllife.model import MPNNPredictor\n",
        "\n",
        "args['device'] = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "set_random_seed(args['random_seed'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJf2RePJHUcx",
        "colab_type": "code",
        "outputId": "952d0756-7503-4c44-e6b9-7d412daa8771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "from dgllife.utils.splitters import ScaffoldSplitter\n",
        "\n",
        "train_scaffold_set, val_set, test_scaffold_set = ScaffoldSplitter.train_val_test_split(train_set, frac_train=0.8, frac_val=0.2,frac_test=0.0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start initializing RDKit molecule instances...\n",
            "Creating RDKit molecule instance 1000/11999\n",
            "Creating RDKit molecule instance 2000/11999\n",
            "Creating RDKit molecule instance 3000/11999\n",
            "Creating RDKit molecule instance 4000/11999\n",
            "Creating RDKit molecule instance 5000/11999\n",
            "Creating RDKit molecule instance 6000/11999\n",
            "Creating RDKit molecule instance 7000/11999\n",
            "Creating RDKit molecule instance 8000/11999\n",
            "Creating RDKit molecule instance 9000/11999\n",
            "Creating RDKit molecule instance 10000/11999\n",
            "Creating RDKit molecule instance 11000/11999\n",
            "Start computing Bemis-Murcko scaffolds.\n",
            "Computing Bemis-Murcko for compound 1000/11999\n",
            "Computing Bemis-Murcko for compound 2000/11999\n",
            "Computing Bemis-Murcko for compound 3000/11999\n",
            "Computing Bemis-Murcko for compound 4000/11999\n",
            "Computing Bemis-Murcko for compound 5000/11999\n",
            "Computing Bemis-Murcko for compound 6000/11999\n",
            "Computing Bemis-Murcko for compound 7000/11999\n",
            "Computing Bemis-Murcko for compound 8000/11999\n",
            "Computing Bemis-Murcko for compound 9000/11999\n",
            "Computing Bemis-Murcko for compound 10000/11999\n",
            "Computing Bemis-Murcko for compound 11000/11999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCmuQegvJMcq",
        "colab_type": "code",
        "outputId": "b3ec3539-a69c-483c-9c3b-f894f6ca5f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "print (len(train_set))\n",
        "print(len(train_scaffold_set))\n",
        "print (len(val_set))\n",
        "print (len(test_set))\n",
        "print(train_set[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11999\n",
            "9599\n",
            "2400\n",
            "880\n",
            "('CC(C)(C)C1=CC=C(C=C1)N(C(C2=CN=NC=C2)C(=O)NC(C)(C)C)C(=O)C3=CC=CO3', DGLGraph(num_nodes=32, num_edges=68,\n",
            "         ndata_schemes={'hv': Scheme(shape=(39,), dtype=torch.float32)}\n",
            "         edata_schemes={'he': Scheme(shape=(10,), dtype=torch.float32)}), tensor([1.]), tensor([1.]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YjAjoUyLEjT",
        "colab_type": "code",
        "outputId": "6b31e928-43b7-4fc2-a792-7c30a9af014e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(type(train_set))\n",
        "print(type(train_scaffold_set))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dgllife.data.csv_dataset.MoleculeCSVDataset'>\n",
            "<class 'dgl.data.utils.Subset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYfHiYl0T8V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_scaffold_set,  batch_size=args['batch_size'],\n",
        "                              collate_fn=collate_molgraphs)\n",
        "val_loader = DataLoader(val_set,  batch_size=args['batch_size'],\n",
        "                              collate_fn=collate_molgraphs)\n",
        "\n",
        "test_loader = DataLoader(test_set,  batch_size=args['batch_size'],\n",
        "                          collate_fn=collate_molgraphs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzUMvJO8Qx85",
        "colab_type": "code",
        "outputId": "4acc8709-5777-4335-e3d2-be7ec77637e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(test_loader))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV6QrE0ltd7M",
        "colab_type": "code",
        "outputId": "8913b5f2-bb3d-406a-c390-6f7e63dca31f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(args['node_featurizer'].feat_size('hv'))\n",
        "print(args['edge_featurizer'].feat_size('he'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGAUIdpRUAUu",
        "colab_type": "code",
        "outputId": "a4d75a72-2968-4b51-b38f-65786cd7d827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "args['n_tasks'] = 1\n",
        "\n",
        "from dgllife.model import AttentiveFPPredictor\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "model = AttentiveFPPredictor(node_feat_size=args['node_featurizer'].feat_size('hv'),\n",
        "                              edge_feat_size=args['edge_featurizer'].feat_size('he'),\n",
        "                              num_layers=args['num_layers'],\n",
        "                              num_timesteps=args['num_timesteps'],\n",
        "                              graph_feat_size=args['graph_feat_size'],\n",
        "                              n_tasks=args['n_tasks'],\n",
        "                              dropout=args['dropout'])\n",
        "\n",
        "'''\n",
        "\n",
        "model = GATPredictor(in_feats=args['node_featurizer'].feat_size('h'),\n",
        "                             hidden_feats=args['gat_hidden_feats'],\n",
        "                             num_heads=args['num_heads'],\n",
        "                             classifier_hidden_feats=args['classifier_hidden_feats'],\n",
        "                             n_tasks=args['n_tasks'])\n",
        "\n",
        "'''\n",
        "\n",
        "import dgl.backend as F\n",
        "\n",
        "train_num_pos = F.sum(train_set.labels, dim=0)\n",
        "train_num_indices = F.sum(train_set.mask, dim=0)\n",
        "train_task_pos_weights = (train_num_indices - train_num_pos) / train_num_pos\n",
        "\n",
        "loss_criterion = nn.MSELoss(reduction='none')\n",
        "\n",
        "'''\n",
        "loss_criterion = BCEWithLogitsLoss(pos_weight=train_task_pos_weights.to(args['device']),\n",
        "                                    reduction='none')\n",
        "'''\n",
        "optimizer = Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "stopper = EarlyStopping(patience=args['patience'], mode='higher', filename='/content/drive/My Drive/Project De Novo/AttentionFP/train_regression.pth')\n",
        "model.to(args['device'])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentiveFPPredictor(\n",
              "  (gnn): AttentiveFPGNN(\n",
              "    (init_context): GetContext(\n",
              "      (project_node): Sequential(\n",
              "        (0): Linear(in_features=39, out_features=200, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "      (project_edge1): Sequential(\n",
              "        (0): Linear(in_features=49, out_features=200, bias=True)\n",
              "        (1): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "      (project_edge2): Sequential(\n",
              "        (0): Dropout(p=0.2, inplace=False)\n",
              "        (1): Linear(in_features=400, out_features=1, bias=True)\n",
              "        (2): LeakyReLU(negative_slope=0.01)\n",
              "      )\n",
              "      (attentive_gru): AttentiveGRU1(\n",
              "        (edge_transform): Sequential(\n",
              "          (0): Dropout(p=0.2, inplace=False)\n",
              "          (1): Linear(in_features=200, out_features=200, bias=True)\n",
              "        )\n",
              "        (gru): GRUCell(200, 200)\n",
              "      )\n",
              "    )\n",
              "    (gnn_layers): ModuleList(\n",
              "      (0): GNNLayer(\n",
              "        (project_edge): Sequential(\n",
              "          (0): Dropout(p=0.2, inplace=False)\n",
              "          (1): Linear(in_features=400, out_features=1, bias=True)\n",
              "          (2): LeakyReLU(negative_slope=0.01)\n",
              "        )\n",
              "        (attentive_gru): AttentiveGRU2(\n",
              "          (project_node): Sequential(\n",
              "            (0): Dropout(p=0.2, inplace=False)\n",
              "            (1): Linear(in_features=200, out_features=200, bias=True)\n",
              "          )\n",
              "          (gru): GRUCell(200, 200)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (readout): AttentiveFPReadout(\n",
              "    (readouts): ModuleList(\n",
              "      (0): GlobalPool(\n",
              "        (compute_logits): Sequential(\n",
              "          (0): Linear(in_features=400, out_features=1, bias=True)\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "        )\n",
              "        (project_nodes): Sequential(\n",
              "          (0): Dropout(p=0.2, inplace=False)\n",
              "          (1): Linear(in_features=200, out_features=200, bias=True)\n",
              "        )\n",
              "        (gru): GRUCell(200, 200)\n",
              "      )\n",
              "      (1): GlobalPool(\n",
              "        (compute_logits): Sequential(\n",
              "          (0): Linear(in_features=400, out_features=1, bias=True)\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "        )\n",
              "        (project_nodes): Sequential(\n",
              "          (0): Dropout(p=0.2, inplace=False)\n",
              "          (1): Linear(in_features=200, out_features=200, bias=True)\n",
              "        )\n",
              "        (gru): GRUCell(200, 200)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (predict): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=200, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Fdo_NxLPWz",
        "colab_type": "code",
        "outputId": "a9166f79-e54e-4fd5-8370-c98737ab75b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(train_task_pos_weights)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([25.9036])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C941OCzRuXH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regress(args, model, bg):\n",
        "    if args['model'] == 'MPNN':\n",
        "        h = bg.ndata.pop('n_feat')\n",
        "        e = bg.edata.pop('e_feat')\n",
        "        h, e = h.to(args['device']), e.to(args['device'])\n",
        "        return model(bg, h, e)\n",
        "    elif args['model'] in ['SchNet', 'MGCN']:\n",
        "        node_types = bg.ndata.pop('node_type')\n",
        "        edge_distances = bg.edata.pop('distance')\n",
        "        node_types, edge_distances = node_types.to(args['device']), \\\n",
        "                                     edge_distances.to(args['device'])\n",
        "        return model(bg, node_types, edge_distances)\n",
        "    else:\n",
        "        atom_feats, bond_feats = bg.ndata.pop('hv'), bg.edata.pop('he')\n",
        "        atom_feats, bond_feats = atom_feats.to(args['device']), bond_feats.to(args['device'])\n",
        "        return model(bg, atom_feats, bond_feats)\n",
        "\n",
        "def predict(args, model, bg):\n",
        "    node_feats = bg.ndata.pop(args['node_data_field']).to(args['device'])\n",
        "    if args.get('edge_featurizer', None) is not None:\n",
        "        edge_feats = bg.edata.pop(args['edge_data_field']).to(args['device'])\n",
        "        return model(bg, node_feats, edge_feats)\n",
        "    else:\n",
        "        return model(bg, node_feats)\n",
        "\n",
        "def run_a_train_epoch(args, epoch, model, data_loader, loss_criterion, optimizer):\n",
        "    model.train()\n",
        "    train_meter = Meter()\n",
        "    for batch_id, batch_data in enumerate(data_loader):\n",
        "        smiles, bg, labels, masks = batch_data\n",
        "        labels, masks = labels.to(args['device']), masks.to(args['device'])\n",
        "        prediction = regress(args, model, bg)\n",
        "        # Mask non-existing labels\n",
        "        loss = (loss_criterion(prediction, labels) * (masks != 0).float()).mean()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_meter.update(prediction, labels, masks)\n",
        "    train_score = np.mean(train_meter.compute_metric(args['metric_name']))\n",
        "    print('epoch {:d}/{:d}, training {} {:.4f}'.format(\n",
        "        epoch + 1, args['num_epochs'], args['metric_name'], train_score))\n",
        "\n",
        "def run_an_eval_epoch(args, model, data_loader):\n",
        "    model.eval()\n",
        "    eval_meter = Meter()\n",
        "    with torch.no_grad():\n",
        "        for batch_id, batch_data in enumerate(data_loader):\n",
        "            smiles, bg, labels, masks = batch_data\n",
        "            labels = labels.to(args['device'])\n",
        "            prediction = regress(args, model, bg)\n",
        "            eval_meter.update(prediction, labels, masks)\n",
        "    return np.mean(eval_meter.compute_metric(args['metric_name']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLkl062SLtaF",
        "colab_type": "code",
        "outputId": "13efdf95-26b4-454d-fe09-d05a68a2a340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "args['device'] = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "args"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 128,\n",
              " 'device': device(type='cuda'),\n",
              " 'dropout': 0.2,\n",
              " 'edge_data_field': 'he',\n",
              " 'edge_feat_size': 10,\n",
              " 'edge_featurizer': <dgllife.utils.featurizers.BaseBondFeaturizer at 0x7ff863744c88>,\n",
              " 'frac_test': 0.1,\n",
              " 'frac_train': 0.8,\n",
              " 'frac_val': 0.1,\n",
              " 'graph_feat_size': 200,\n",
              " 'lr': 0.0031622776601683794,\n",
              " 'metric_name': 'roc_auc_score',\n",
              " 'model': 'AttentiveFPPredictor',\n",
              " 'n_tasks': 1,\n",
              " 'node_data_field': 'hv',\n",
              " 'node_feat_size': 39,\n",
              " 'node_featurizer': <dgllife.utils.featurizers.BaseAtomFeaturizer at 0x7ff863744c50>,\n",
              " 'num_epochs': 800,\n",
              " 'num_layers': 2,\n",
              " 'num_timesteps': 2,\n",
              " 'patience': 80,\n",
              " 'random_seed': 8,\n",
              " 'smiles_to_graph': <function dgllife.utils.mol_to_graph.smiles_to_bigraph>,\n",
              " 'weight_decay': 1e-05}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73ZBLfQxuHQA",
        "colab_type": "code",
        "outputId": "39c116c1-1c6a-4f04-ab4e-e38a7fd624aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(args['num_epochs']):\n",
        "        # Train\n",
        "        run_a_train_epoch(args, epoch, model, train_loader, loss_criterion, optimizer)\n",
        "\n",
        "        # Validation and early stop\n",
        "        val_score = run_an_eval_epoch(args, model, val_loader)\n",
        "        early_stop = stopper.step(val_score, model)\n",
        "        print('epoch {:d}/{:d}, validation {} {:.4f}, best validation {} {:.4f}'.format(\n",
        "            epoch + 1, args['num_epochs'], args['metric_name'],\n",
        "            val_score, args['metric_name'], stopper.best_score))\n",
        "        if early_stop:\n",
        "            break"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1/800, training roc_auc_score 0.2901\n",
            "epoch 1/800, validation roc_auc_score 0.4034, best validation roc_auc_score 0.4034\n",
            "epoch 2/800, training roc_auc_score 0.3239\n",
            "epoch 2/800, validation roc_auc_score 0.5949, best validation roc_auc_score 0.5949\n",
            "epoch 3/800, training roc_auc_score 0.3513\n",
            "epoch 3/800, validation roc_auc_score 0.6504, best validation roc_auc_score 0.6504\n",
            "epoch 4/800, training roc_auc_score 0.3540\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 4/800, validation roc_auc_score 0.6063, best validation roc_auc_score 0.6504\n",
            "epoch 5/800, training roc_auc_score 0.3196\n",
            "EarlyStopping counter: 2 out of 80\n",
            "epoch 5/800, validation roc_auc_score 0.6179, best validation roc_auc_score 0.6504\n",
            "epoch 6/800, training roc_auc_score 0.3147\n",
            "EarlyStopping counter: 3 out of 80\n",
            "epoch 6/800, validation roc_auc_score 0.6389, best validation roc_auc_score 0.6504\n",
            "epoch 7/800, training roc_auc_score 0.3234\n",
            "EarlyStopping counter: 4 out of 80\n",
            "epoch 7/800, validation roc_auc_score 0.5390, best validation roc_auc_score 0.6504\n",
            "epoch 8/800, training roc_auc_score 0.2199\n",
            "EarlyStopping counter: 5 out of 80\n",
            "epoch 8/800, validation roc_auc_score 0.6420, best validation roc_auc_score 0.6504\n",
            "epoch 9/800, training roc_auc_score 0.3129\n",
            "EarlyStopping counter: 6 out of 80\n",
            "epoch 9/800, validation roc_auc_score 0.4976, best validation roc_auc_score 0.6504\n",
            "epoch 10/800, training roc_auc_score 0.3078\n",
            "EarlyStopping counter: 7 out of 80\n",
            "epoch 10/800, validation roc_auc_score 0.3254, best validation roc_auc_score 0.6504\n",
            "epoch 11/800, training roc_auc_score 0.2818\n",
            "epoch 11/800, validation roc_auc_score 0.6746, best validation roc_auc_score 0.6746\n",
            "epoch 12/800, training roc_auc_score 0.2801\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 12/800, validation roc_auc_score 0.6483, best validation roc_auc_score 0.6746\n",
            "epoch 13/800, training roc_auc_score 0.3094\n",
            "EarlyStopping counter: 2 out of 80\n",
            "epoch 13/800, validation roc_auc_score 0.5686, best validation roc_auc_score 0.6746\n",
            "epoch 14/800, training roc_auc_score 0.3133\n",
            "EarlyStopping counter: 3 out of 80\n",
            "epoch 14/800, validation roc_auc_score 0.6592, best validation roc_auc_score 0.6746\n",
            "epoch 15/800, training roc_auc_score 0.3221\n",
            "EarlyStopping counter: 4 out of 80\n",
            "epoch 15/800, validation roc_auc_score 0.6712, best validation roc_auc_score 0.6746\n",
            "epoch 16/800, training roc_auc_score 0.3103\n",
            "epoch 16/800, validation roc_auc_score 0.6751, best validation roc_auc_score 0.6751\n",
            "epoch 17/800, training roc_auc_score 0.2987\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 17/800, validation roc_auc_score 0.3173, best validation roc_auc_score 0.6751\n",
            "epoch 18/800, training roc_auc_score 0.3098\n",
            "epoch 18/800, validation roc_auc_score 0.6868, best validation roc_auc_score 0.6868\n",
            "epoch 19/800, training roc_auc_score 0.2955\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 19/800, validation roc_auc_score 0.6763, best validation roc_auc_score 0.6868\n",
            "epoch 20/800, training roc_auc_score 0.4037\n",
            "EarlyStopping counter: 2 out of 80\n",
            "epoch 20/800, validation roc_auc_score 0.4089, best validation roc_auc_score 0.6868\n",
            "epoch 21/800, training roc_auc_score 0.3101\n",
            "epoch 21/800, validation roc_auc_score 0.6965, best validation roc_auc_score 0.6965\n",
            "epoch 22/800, training roc_auc_score 0.3606\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 22/800, validation roc_auc_score 0.5550, best validation roc_auc_score 0.6965\n",
            "epoch 23/800, training roc_auc_score 0.4758\n",
            "EarlyStopping counter: 2 out of 80\n",
            "epoch 23/800, validation roc_auc_score 0.5047, best validation roc_auc_score 0.6965\n",
            "epoch 24/800, training roc_auc_score 0.4364\n",
            "epoch 24/800, validation roc_auc_score 0.7285, best validation roc_auc_score 0.7285\n",
            "epoch 25/800, training roc_auc_score 0.4721\n",
            "epoch 25/800, validation roc_auc_score 0.7336, best validation roc_auc_score 0.7336\n",
            "epoch 26/800, training roc_auc_score 0.5158\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 26/800, validation roc_auc_score 0.7316, best validation roc_auc_score 0.7336\n",
            "epoch 27/800, training roc_auc_score 0.5234\n",
            "EarlyStopping counter: 2 out of 80\n",
            "epoch 27/800, validation roc_auc_score 0.5635, best validation roc_auc_score 0.7336\n",
            "epoch 28/800, training roc_auc_score 0.5410\n",
            "epoch 28/800, validation roc_auc_score 0.7359, best validation roc_auc_score 0.7359\n",
            "epoch 29/800, training roc_auc_score 0.5416\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 29/800, validation roc_auc_score 0.7243, best validation roc_auc_score 0.7359\n",
            "epoch 30/800, training roc_auc_score 0.5518\n",
            "EarlyStopping counter: 2 out of 80\n",
            "epoch 30/800, validation roc_auc_score 0.7127, best validation roc_auc_score 0.7359\n",
            "epoch 31/800, training roc_auc_score 0.5555\n",
            "epoch 31/800, validation roc_auc_score 0.7424, best validation roc_auc_score 0.7424\n",
            "epoch 32/800, training roc_auc_score 0.5626\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 32/800, validation roc_auc_score 0.6939, best validation roc_auc_score 0.7424\n",
            "epoch 33/800, training roc_auc_score 0.5638\n",
            "epoch 33/800, validation roc_auc_score 0.7485, best validation roc_auc_score 0.7485\n",
            "epoch 34/800, training roc_auc_score 0.5889\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 34/800, validation roc_auc_score 0.7409, best validation roc_auc_score 0.7485\n",
            "epoch 35/800, training roc_auc_score 0.5678\n",
            "EarlyStopping counter: 2 out of 80\n",
            "epoch 35/800, validation roc_auc_score 0.7427, best validation roc_auc_score 0.7485\n",
            "epoch 36/800, training roc_auc_score 0.5978\n",
            "EarlyStopping counter: 3 out of 80\n",
            "epoch 36/800, validation roc_auc_score 0.7481, best validation roc_auc_score 0.7485\n",
            "epoch 37/800, training roc_auc_score 0.6533\n",
            "EarlyStopping counter: 4 out of 80\n",
            "epoch 37/800, validation roc_auc_score 0.6283, best validation roc_auc_score 0.7485\n",
            "epoch 38/800, training roc_auc_score 0.6254\n",
            "epoch 38/800, validation roc_auc_score 0.7526, best validation roc_auc_score 0.7526\n",
            "epoch 39/800, training roc_auc_score 0.6375\n",
            "epoch 39/800, validation roc_auc_score 0.7873, best validation roc_auc_score 0.7873\n",
            "epoch 40/800, training roc_auc_score 0.6831\n",
            "epoch 40/800, validation roc_auc_score 0.7953, best validation roc_auc_score 0.7953\n",
            "epoch 41/800, training roc_auc_score 0.7170\n",
            "epoch 41/800, validation roc_auc_score 0.7963, best validation roc_auc_score 0.7963\n",
            "epoch 42/800, training roc_auc_score 0.7423\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 42/800, validation roc_auc_score 0.7951, best validation roc_auc_score 0.7963\n",
            "epoch 43/800, training roc_auc_score 0.7375\n",
            "epoch 43/800, validation roc_auc_score 0.8174, best validation roc_auc_score 0.8174\n",
            "epoch 44/800, training roc_auc_score 0.7326\n",
            "EarlyStopping counter: 1 out of 80\n",
            "epoch 44/800, validation roc_auc_score 0.7231, best validation roc_auc_score 0.8174\n",
            "epoch 45/800, training roc_auc_score 0.7537\n",
            "EarlyStopping counter: 2 out of 80\n",
            "epoch 45/800, validation roc_auc_score 0.8044, best validation roc_auc_score 0.8174\n",
            "epoch 46/800, training roc_auc_score 0.6822\n",
            "EarlyStopping counter: 3 out of 80\n",
            "epoch 46/800, validation roc_auc_score 0.8005, best validation roc_auc_score 0.8174\n",
            "epoch 47/800, training roc_auc_score 0.7251\n",
            "EarlyStopping counter: 4 out of 80\n",
            "epoch 47/800, validation roc_auc_score 0.7860, best validation roc_auc_score 0.8174\n",
            "epoch 48/800, training roc_auc_score 0.7509\n",
            "EarlyStopping counter: 5 out of 80\n",
            "epoch 48/800, validation roc_auc_score 0.7950, best validation roc_auc_score 0.8174\n",
            "epoch 49/800, training roc_auc_score 0.7412\n",
            "EarlyStopping counter: 6 out of 80\n",
            "epoch 49/800, validation roc_auc_score 0.7976, best validation roc_auc_score 0.8174\n",
            "epoch 50/800, training roc_auc_score 0.7677\n",
            "EarlyStopping counter: 7 out of 80\n",
            "epoch 50/800, validation roc_auc_score 0.4015, best validation roc_auc_score 0.8174\n",
            "epoch 51/800, training roc_auc_score 0.7413\n",
            "EarlyStopping counter: 8 out of 80\n",
            "epoch 51/800, validation roc_auc_score 0.7962, best validation roc_auc_score 0.8174\n",
            "epoch 52/800, training roc_auc_score 0.7892\n",
            "EarlyStopping counter: 9 out of 80\n",
            "epoch 52/800, validation roc_auc_score 0.7841, best validation roc_auc_score 0.8174\n",
            "epoch 53/800, training roc_auc_score 0.7740\n",
            "EarlyStopping counter: 10 out of 80\n",
            "epoch 53/800, validation roc_auc_score 0.7003, best validation roc_auc_score 0.8174\n",
            "epoch 54/800, training roc_auc_score 0.7387\n",
            "EarlyStopping counter: 11 out of 80\n",
            "epoch 54/800, validation roc_auc_score 0.5256, best validation roc_auc_score 0.8174\n",
            "epoch 55/800, training roc_auc_score 0.7493\n",
            "EarlyStopping counter: 12 out of 80\n",
            "epoch 55/800, validation roc_auc_score 0.7941, best validation roc_auc_score 0.8174\n",
            "epoch 56/800, training roc_auc_score 0.7928\n",
            "EarlyStopping counter: 13 out of 80\n",
            "epoch 56/800, validation roc_auc_score 0.7955, best validation roc_auc_score 0.8174\n",
            "epoch 57/800, training roc_auc_score 0.7558\n",
            "EarlyStopping counter: 14 out of 80\n",
            "epoch 57/800, validation roc_auc_score 0.4979, best validation roc_auc_score 0.8174\n",
            "epoch 58/800, training roc_auc_score 0.7656\n",
            "EarlyStopping counter: 15 out of 80\n",
            "epoch 58/800, validation roc_auc_score 0.7051, best validation roc_auc_score 0.8174\n",
            "epoch 59/800, training roc_auc_score 0.7772\n",
            "EarlyStopping counter: 16 out of 80\n",
            "epoch 59/800, validation roc_auc_score 0.7491, best validation roc_auc_score 0.8174\n",
            "epoch 60/800, training roc_auc_score 0.7627\n",
            "EarlyStopping counter: 17 out of 80\n",
            "epoch 60/800, validation roc_auc_score 0.5364, best validation roc_auc_score 0.8174\n",
            "epoch 61/800, training roc_auc_score 0.7250\n",
            "EarlyStopping counter: 18 out of 80\n",
            "epoch 61/800, validation roc_auc_score 0.5232, best validation roc_auc_score 0.8174\n",
            "epoch 62/800, training roc_auc_score 0.7458\n",
            "EarlyStopping counter: 19 out of 80\n",
            "epoch 62/800, validation roc_auc_score 0.5585, best validation roc_auc_score 0.8174\n",
            "epoch 63/800, training roc_auc_score 0.7248\n",
            "EarlyStopping counter: 20 out of 80\n",
            "epoch 63/800, validation roc_auc_score 0.7279, best validation roc_auc_score 0.8174\n",
            "epoch 64/800, training roc_auc_score 0.7487\n",
            "EarlyStopping counter: 21 out of 80\n",
            "epoch 64/800, validation roc_auc_score 0.5237, best validation roc_auc_score 0.8174\n",
            "epoch 65/800, training roc_auc_score 0.6811\n",
            "EarlyStopping counter: 22 out of 80\n",
            "epoch 65/800, validation roc_auc_score 0.6694, best validation roc_auc_score 0.8174\n",
            "epoch 66/800, training roc_auc_score 0.6851\n",
            "EarlyStopping counter: 23 out of 80\n",
            "epoch 66/800, validation roc_auc_score 0.6486, best validation roc_auc_score 0.8174\n",
            "epoch 67/800, training roc_auc_score 0.6816\n",
            "EarlyStopping counter: 24 out of 80\n",
            "epoch 67/800, validation roc_auc_score 0.6890, best validation roc_auc_score 0.8174\n",
            "epoch 68/800, training roc_auc_score 0.7225\n",
            "EarlyStopping counter: 25 out of 80\n",
            "epoch 68/800, validation roc_auc_score 0.7856, best validation roc_auc_score 0.8174\n",
            "epoch 69/800, training roc_auc_score 0.7638\n",
            "EarlyStopping counter: 26 out of 80\n",
            "epoch 69/800, validation roc_auc_score 0.6926, best validation roc_auc_score 0.8174\n",
            "epoch 70/800, training roc_auc_score 0.7632\n",
            "EarlyStopping counter: 27 out of 80\n",
            "epoch 70/800, validation roc_auc_score 0.5519, best validation roc_auc_score 0.8174\n",
            "epoch 71/800, training roc_auc_score 0.7476\n",
            "EarlyStopping counter: 28 out of 80\n",
            "epoch 71/800, validation roc_auc_score 0.7904, best validation roc_auc_score 0.8174\n",
            "epoch 72/800, training roc_auc_score 0.7797\n",
            "EarlyStopping counter: 29 out of 80\n",
            "epoch 72/800, validation roc_auc_score 0.7832, best validation roc_auc_score 0.8174\n",
            "epoch 73/800, training roc_auc_score 0.7517\n",
            "EarlyStopping counter: 30 out of 80\n",
            "epoch 73/800, validation roc_auc_score 0.8116, best validation roc_auc_score 0.8174\n",
            "epoch 74/800, training roc_auc_score 0.7258\n",
            "EarlyStopping counter: 31 out of 80\n",
            "epoch 74/800, validation roc_auc_score 0.7378, best validation roc_auc_score 0.8174\n",
            "epoch 75/800, training roc_auc_score 0.7702\n",
            "EarlyStopping counter: 32 out of 80\n",
            "epoch 75/800, validation roc_auc_score 0.4915, best validation roc_auc_score 0.8174\n",
            "epoch 76/800, training roc_auc_score 0.7797\n",
            "EarlyStopping counter: 33 out of 80\n",
            "epoch 76/800, validation roc_auc_score 0.7979, best validation roc_auc_score 0.8174\n",
            "epoch 77/800, training roc_auc_score 0.7422\n",
            "EarlyStopping counter: 34 out of 80\n",
            "epoch 77/800, validation roc_auc_score 0.7175, best validation roc_auc_score 0.8174\n",
            "epoch 78/800, training roc_auc_score 0.7663\n",
            "EarlyStopping counter: 35 out of 80\n",
            "epoch 78/800, validation roc_auc_score 0.7651, best validation roc_auc_score 0.8174\n",
            "epoch 79/800, training roc_auc_score 0.7472\n",
            "EarlyStopping counter: 36 out of 80\n",
            "epoch 79/800, validation roc_auc_score 0.7655, best validation roc_auc_score 0.8174\n",
            "epoch 80/800, training roc_auc_score 0.7786\n",
            "EarlyStopping counter: 37 out of 80\n",
            "epoch 80/800, validation roc_auc_score 0.7697, best validation roc_auc_score 0.8174\n",
            "epoch 81/800, training roc_auc_score 0.7689\n",
            "EarlyStopping counter: 38 out of 80\n",
            "epoch 81/800, validation roc_auc_score 0.7538, best validation roc_auc_score 0.8174\n",
            "epoch 82/800, training roc_auc_score 0.7608\n",
            "EarlyStopping counter: 39 out of 80\n",
            "epoch 82/800, validation roc_auc_score 0.7220, best validation roc_auc_score 0.8174\n",
            "epoch 83/800, training roc_auc_score 0.7554\n",
            "EarlyStopping counter: 40 out of 80\n",
            "epoch 83/800, validation roc_auc_score 0.5634, best validation roc_auc_score 0.8174\n",
            "epoch 84/800, training roc_auc_score 0.7395\n",
            "EarlyStopping counter: 41 out of 80\n",
            "epoch 84/800, validation roc_auc_score 0.7607, best validation roc_auc_score 0.8174\n",
            "epoch 85/800, training roc_auc_score 0.7488\n",
            "EarlyStopping counter: 42 out of 80\n",
            "epoch 85/800, validation roc_auc_score 0.7168, best validation roc_auc_score 0.8174\n",
            "epoch 86/800, training roc_auc_score 0.7719\n",
            "EarlyStopping counter: 43 out of 80\n",
            "epoch 86/800, validation roc_auc_score 0.6865, best validation roc_auc_score 0.8174\n",
            "epoch 87/800, training roc_auc_score 0.7533\n",
            "EarlyStopping counter: 44 out of 80\n",
            "epoch 87/800, validation roc_auc_score 0.7023, best validation roc_auc_score 0.8174\n",
            "epoch 88/800, training roc_auc_score 0.7694\n",
            "EarlyStopping counter: 45 out of 80\n",
            "epoch 88/800, validation roc_auc_score 0.6966, best validation roc_auc_score 0.8174\n",
            "epoch 89/800, training roc_auc_score 0.7624\n",
            "EarlyStopping counter: 46 out of 80\n",
            "epoch 89/800, validation roc_auc_score 0.7583, best validation roc_auc_score 0.8174\n",
            "epoch 90/800, training roc_auc_score 0.7612\n",
            "EarlyStopping counter: 47 out of 80\n",
            "epoch 90/800, validation roc_auc_score 0.6638, best validation roc_auc_score 0.8174\n",
            "epoch 91/800, training roc_auc_score 0.7544\n",
            "EarlyStopping counter: 48 out of 80\n",
            "epoch 91/800, validation roc_auc_score 0.7196, best validation roc_auc_score 0.8174\n",
            "epoch 92/800, training roc_auc_score 0.7567\n",
            "EarlyStopping counter: 49 out of 80\n",
            "epoch 92/800, validation roc_auc_score 0.7248, best validation roc_auc_score 0.8174\n",
            "epoch 93/800, training roc_auc_score 0.7625\n",
            "EarlyStopping counter: 50 out of 80\n",
            "epoch 93/800, validation roc_auc_score 0.6793, best validation roc_auc_score 0.8174\n",
            "epoch 94/800, training roc_auc_score 0.7425\n",
            "EarlyStopping counter: 51 out of 80\n",
            "epoch 94/800, validation roc_auc_score 0.6341, best validation roc_auc_score 0.8174\n",
            "epoch 95/800, training roc_auc_score 0.7442\n",
            "EarlyStopping counter: 52 out of 80\n",
            "epoch 95/800, validation roc_auc_score 0.6480, best validation roc_auc_score 0.8174\n",
            "epoch 96/800, training roc_auc_score 0.7440\n",
            "EarlyStopping counter: 53 out of 80\n",
            "epoch 96/800, validation roc_auc_score 0.6730, best validation roc_auc_score 0.8174\n",
            "epoch 97/800, training roc_auc_score 0.7558\n",
            "EarlyStopping counter: 54 out of 80\n",
            "epoch 97/800, validation roc_auc_score 0.3554, best validation roc_auc_score 0.8174\n",
            "epoch 98/800, training roc_auc_score 0.7273\n",
            "EarlyStopping counter: 55 out of 80\n",
            "epoch 98/800, validation roc_auc_score 0.6791, best validation roc_auc_score 0.8174\n",
            "epoch 99/800, training roc_auc_score 0.6564\n",
            "EarlyStopping counter: 56 out of 80\n",
            "epoch 99/800, validation roc_auc_score 0.6203, best validation roc_auc_score 0.8174\n",
            "epoch 100/800, training roc_auc_score 0.7349\n",
            "EarlyStopping counter: 57 out of 80\n",
            "epoch 100/800, validation roc_auc_score 0.7010, best validation roc_auc_score 0.8174\n",
            "epoch 101/800, training roc_auc_score 0.7416\n",
            "EarlyStopping counter: 58 out of 80\n",
            "epoch 101/800, validation roc_auc_score 0.7270, best validation roc_auc_score 0.8174\n",
            "epoch 102/800, training roc_auc_score 0.7661\n",
            "EarlyStopping counter: 59 out of 80\n",
            "epoch 102/800, validation roc_auc_score 0.7008, best validation roc_auc_score 0.8174\n",
            "epoch 103/800, training roc_auc_score 0.7402\n",
            "EarlyStopping counter: 60 out of 80\n",
            "epoch 103/800, validation roc_auc_score 0.7210, best validation roc_auc_score 0.8174\n",
            "epoch 104/800, training roc_auc_score 0.7785\n",
            "EarlyStopping counter: 61 out of 80\n",
            "epoch 104/800, validation roc_auc_score 0.7639, best validation roc_auc_score 0.8174\n",
            "epoch 105/800, training roc_auc_score 0.7855\n",
            "EarlyStopping counter: 62 out of 80\n",
            "epoch 105/800, validation roc_auc_score 0.7183, best validation roc_auc_score 0.8174\n",
            "epoch 106/800, training roc_auc_score 0.7032\n",
            "EarlyStopping counter: 63 out of 80\n",
            "epoch 106/800, validation roc_auc_score 0.7314, best validation roc_auc_score 0.8174\n",
            "epoch 107/800, training roc_auc_score 0.7618\n",
            "EarlyStopping counter: 64 out of 80\n",
            "epoch 107/800, validation roc_auc_score 0.6291, best validation roc_auc_score 0.8174\n",
            "epoch 108/800, training roc_auc_score 0.7099\n",
            "EarlyStopping counter: 65 out of 80\n",
            "epoch 108/800, validation roc_auc_score 0.7080, best validation roc_auc_score 0.8174\n",
            "epoch 109/800, training roc_auc_score 0.7296\n",
            "EarlyStopping counter: 66 out of 80\n",
            "epoch 109/800, validation roc_auc_score 0.6576, best validation roc_auc_score 0.8174\n",
            "epoch 110/800, training roc_auc_score 0.7944\n",
            "EarlyStopping counter: 67 out of 80\n",
            "epoch 110/800, validation roc_auc_score 0.5881, best validation roc_auc_score 0.8174\n",
            "epoch 111/800, training roc_auc_score 0.6691\n",
            "EarlyStopping counter: 68 out of 80\n",
            "epoch 111/800, validation roc_auc_score 0.6785, best validation roc_auc_score 0.8174\n",
            "epoch 112/800, training roc_auc_score 0.7336\n",
            "EarlyStopping counter: 69 out of 80\n",
            "epoch 112/800, validation roc_auc_score 0.7004, best validation roc_auc_score 0.8174\n",
            "epoch 113/800, training roc_auc_score 0.7532\n",
            "EarlyStopping counter: 70 out of 80\n",
            "epoch 113/800, validation roc_auc_score 0.7166, best validation roc_auc_score 0.8174\n",
            "epoch 114/800, training roc_auc_score 0.7738\n",
            "EarlyStopping counter: 71 out of 80\n",
            "epoch 114/800, validation roc_auc_score 0.7193, best validation roc_auc_score 0.8174\n",
            "epoch 115/800, training roc_auc_score 0.7741\n",
            "EarlyStopping counter: 72 out of 80\n",
            "epoch 115/800, validation roc_auc_score 0.7166, best validation roc_auc_score 0.8174\n",
            "epoch 116/800, training roc_auc_score 0.7796\n",
            "EarlyStopping counter: 73 out of 80\n",
            "epoch 116/800, validation roc_auc_score 0.7250, best validation roc_auc_score 0.8174\n",
            "epoch 117/800, training roc_auc_score 0.7808\n",
            "EarlyStopping counter: 74 out of 80\n",
            "epoch 117/800, validation roc_auc_score 0.7123, best validation roc_auc_score 0.8174\n",
            "epoch 118/800, training roc_auc_score 0.7865\n",
            "EarlyStopping counter: 75 out of 80\n",
            "epoch 118/800, validation roc_auc_score 0.7296, best validation roc_auc_score 0.8174\n",
            "epoch 119/800, training roc_auc_score 0.7892\n",
            "EarlyStopping counter: 76 out of 80\n",
            "epoch 119/800, validation roc_auc_score 0.7228, best validation roc_auc_score 0.8174\n",
            "epoch 120/800, training roc_auc_score 0.7862\n",
            "EarlyStopping counter: 77 out of 80\n",
            "epoch 120/800, validation roc_auc_score 0.7213, best validation roc_auc_score 0.8174\n",
            "epoch 121/800, training roc_auc_score 0.7732\n",
            "EarlyStopping counter: 78 out of 80\n",
            "epoch 121/800, validation roc_auc_score 0.7235, best validation roc_auc_score 0.8174\n",
            "epoch 122/800, training roc_auc_score 0.7582\n",
            "EarlyStopping counter: 79 out of 80\n",
            "epoch 122/800, validation roc_auc_score 0.7203, best validation roc_auc_score 0.8174\n",
            "epoch 123/800, training roc_auc_score 0.7802\n",
            "EarlyStopping counter: 80 out of 80\n",
            "epoch 123/800, validation roc_auc_score 0.7375, best validation roc_auc_score 0.8174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YaWpHl2Gnr-",
        "colab_type": "code",
        "outputId": "2db4872b-07d3-4e8a-aedb-bbb15514242f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "stopper.load_checkpoint(model)\n",
        "test_score = run_an_eval_epoch(args, model, test_loader)\n",
        "print('test {} {:.4f}'.format(args['metric_name'], test_score))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test roc_auc_score 0.6421\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}